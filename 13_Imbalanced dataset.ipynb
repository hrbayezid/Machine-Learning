{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "272d663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kagglehub as kh\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b07cb8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  Purchased\n",
       "395   46            41000          1\n",
       "396   51            23000          1\n",
       "397   50            20000          1\n",
       "398   36            33000          0\n",
       "399   49            36000          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kh.dataset_download(\"rakeshrau/social-network-ads\")\n",
    "\n",
    "dataset = pd.read_csv(f\"{path}/Social_Network_Ads.csv\")\n",
    "\n",
    "dataset.drop(columns=[\"User ID\",\"Gender\"],axis=1,inplace=True)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f5dad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchased\n",
       "0    257\n",
       "1    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Purchased\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189644f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop(\"Purchased\",axis=1)\n",
    "y = dataset [\"Purchased\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.25,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2a8bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9166640f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample = pd.DataFrame([[46, 41000]], columns=x.columns)\n",
    "lr.predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d703b8a",
   "metadata": {},
   "source": [
    "undersampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchased\n",
       "0    143\n",
       "1    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru = RandomUnderSampler()\n",
    "ru_x,ru_y = ru.fit_resample(x,y)\n",
    "\n",
    "ru_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cd05a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194444444444444"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(ru_x,ru_y,test_size=.25,random_state=42)\n",
    "\n",
    "lr.fit(x_train,y_train)\n",
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c176e19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VICTUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([[36,33000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c4c907",
   "metadata": {},
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d16ccfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875968992248062"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os = RandomOverSampler()\n",
    "\n",
    "os_x,os_y = os.fit_resample(x,y)\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(os_x,os_y,test_size=.25,random_state=42)\n",
    "\n",
    "lr.fit(x_train,y_train)\n",
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20a37f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchased\n",
       "0    257\n",
       "1    257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86ab1e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VICTUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([[36,33000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac32d3",
   "metadata": {},
   "source": [
    "### Notes on Imbalanced Datasets\n",
    "\n",
    "- **Definition:** An imbalanced dataset is one where the classes are not represented equally. Typically, one class (the majority class) has significantly more samples than the other class(es) (the minority class).\n",
    "\n",
    "- **Challenges:**\n",
    "    - Standard machine learning algorithms may be biased towards the majority class.\n",
    "    - Metrics like accuracy can be misleading; alternative metrics such as precision, recall, F1-score, and ROC-AUC are preferred.\n",
    "    - The minority class, often the class of interest, may be under-predicted.\n",
    "\n",
    "- **Common Solutions:**\n",
    "    - **Resampling Techniques:** \n",
    "        - *Oversampling* the minority class (e.g., SMOTE).\n",
    "        - *Undersampling* the majority class.\n",
    "    - **Algorithmic Approaches:** \n",
    "        - Use algorithms that are robust to class imbalance (e.g., tree-based methods).\n",
    "        - Adjust class weights in the loss function.\n",
    "    - **Evaluation Metrics:** \n",
    "        - Use confusion matrix, precision, recall, F1-score, ROC-AUC, and PR-AUC for better assessment.\n",
    "\n",
    "- **Applications:** Fraud detection, medical diagnosis, anomaly detection, etc., where rare events are of high importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092d5ae",
   "metadata": {},
   "source": [
    "### Resampling Techniques for Imbalanced Datasets\n",
    "\n",
    "Resampling techniques are strategies used to adjust the class distribution within a dataset to address class imbalance. The main goal is to provide a more balanced representation of classes, which helps machine learning models learn equally from all classes and improves their predictive performance, especially for the minority class.\n",
    "\n",
    "#### 1. Oversampling\n",
    "\n",
    "- **Definition:** Increases the number of samples in the minority class by replicating existing samples or generating new synthetic samples.\n",
    "- **Methods:**\n",
    "    - **Random Oversampling:** Randomly duplicates examples from the minority class.\n",
    "    - **SMOTE (Synthetic Minority Over-sampling Technique):** Generates synthetic samples by interpolating between existing minority class samples.\n",
    "- **Pros:** Helps models learn more about the minority class.\n",
    "- **Cons:** May lead to overfitting, especially with simple duplication.\n",
    "\n",
    "#### 2. Undersampling\n",
    "\n",
    "- **Definition:** Reduces the number of samples in the majority class by randomly removing samples.\n",
    "- **Methods:**\n",
    "    - **Random Undersampling:** Randomly removes examples from the majority class.\n",
    "    - **Cluster Centroids:** Replaces clusters of majority samples with their centroids.\n",
    "- **Pros:** Reduces training time and memory usage.\n",
    "- **Cons:** Risk of losing important information from the majority class.\n",
    "\n",
    "#### 3. Combination (Hybrid) Methods\n",
    "\n",
    "- **Definition:** Combines both oversampling and undersampling to balance the dataset.\n",
    "- **Example:** First applies SMOTE to oversample the minority class, then randomly undersamples the majority class.\n",
    "\n",
    "#### 4. Advanced Techniques\n",
    "\n",
    "- **Tomek Links:** Removes overlapping samples between classes to clean the decision boundary.\n",
    "- **Edited Nearest Neighbors (ENN):** Removes samples that differ from the majority of their neighbors.\n",
    "\n",
    "#### **When to Use Resampling?**\n",
    "\n",
    "- When the dataset is highly imbalanced and standard algorithms perform poorly on the minority class.\n",
    "- When evaluation metrics (like recall or F1-score) for the minority class are low.\n",
    "\n",
    "**Note:** Always apply resampling techniques only to the training set to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f55e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
